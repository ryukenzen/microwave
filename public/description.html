<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="date" content="2020-05-24" />
  <title>A New Data Set :: Microwave Sensor Actions</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="github.css" type="text/css" />
</head>
<body>
<div id="header">
<h1 class="title">A New Data Set :: Microwave Sensor Actions</h1>
<h3 class="date">May 24, 2020</h3>
</div>
<h1 id="dataset-description">DATASET DESCRIPTION</h1>
<p>We introduce a new microwave sensor dataset which captures multiple persons performing multiple actions at the same time.</p>
<p>Compared with traditional camera videos, the data set only contains reflection signals without any visible information in a specific 3D space centered at the sensor. Thus, privacy intrusion can be avoided. When we build the data set, we take into account the reality of action recognition. It is likely that multiple actions may happen at the same time, thus we could only provide multiple labels which tell what actions happened in one <code>video' clip [1]. Since labeling data is a time-consuming and labor-intensive job, and the microwave signals are invisible, it is impossible to precisely mark the bounding box of each individual action. In this data set, the labels are only given at the level of</code>video' clip [1].</p>
<p>In contrast to most camera videos and a few small wireless data sets that only provide single-person actions, our data set provides a large number of multi-person actions following the recent work for multi-person action recognition in 360-degree videos [J. Li, et al., WACV20] . Thus, this data set can be used as a benchmark for action recognition in microwave sensors.</p>
<ul>
<li>[1] <code>video' clip: It is worth noting that we do not use any real videos for   learning. The word of</code>video' is only used for easy understanding to denote contiguous frames of 3D spatial signals.</li>
</ul>
<h2 id="subjects">Subjects</h2>
<p>We invited ten volunteers to join the data set collection at five places with five sensors. These sensors are mounted on the ceiling or on the wall with different background noise and viewpoints.</p>
<h2 id="actions">Actions</h2>
<p>In total, we design ten regular actions, including <code>Wave hands (Wave)',</code>Clap hands (Clap)', <code>Tie the shoes (Tie)',</code>Pick up bag (Pick)', <code>Throw away bag (Throw)',</code>Sit down (Sit)', <code>Stand up (Stand)',</code>Walk (Walk)', <code>Run (Run)', and</code>Carry something (Carry)'. In addition to single-person actions, we also record two-person actions simultaneously, which are difficult to distinguish, such as <code>Walk--Run',</code>Wave--Clap', <code>Tie--Pick', etc. Furthermore, there is also triple-person actions data, such as</code>Walk--Carry--Run'. The 3D sensing space of each sensor is set to 2m x 2m x 1.8m. This means that we collect reflection signals of a 3D space centered at the sensor, with 2 meters in length, 2 meters in width, and 1.8 meters in height.</p>
<p>The number of frames for each data ranges from 34 to 79. For each action data in each mini-batch, we randomly sample 32 continuous frames. Thus, the form of each data for training and testing are both 32x20x80x80.</p>
<p>The image is a simple visualization of one item in corresponding folder. And the data item in folder could be read with MATLAB. The corresponding videos are sampled synchronously with a camera.</p>
<h1 id="samples-of-video-clips">SAMPLES of VIDEO CLIPS</h1>
<ul>
<li>Original size (1200x900)</li>
</ul>
<p>[<a href="carry-throw-sit.png" class="uri">carry-throw-sit.png</a>] | [<a href="run-pick-wave.png" class="uri">run-pick-wave.png</a>] | [<a href="stand-walk-clap.png" class="uri">stand-walk-clap.png</a>] | [<a href="wave-clap-walk.png" class="uri">wave-clap-walk.png</a>]</p>
<ul>
<li>Small size (400x300)</li>
</ul>
<p>[<img src="small/carry-throw-sit.png" alt="carry-throw-sit.png" />] | [<img src="small/run-pick-wave.png" alt="run-pick-wave.png" />] | [<img src="small/stand-walk-clap.png" alt="stand-walk-clap.png" />] | [<img src="small/wave-clap-walk.png" alt="wave-clap-walk.png" />]</p>
<h1 id="structure-of-directory-files">STRUCTURE of DIRECTORY &amp; FILES</h1>
<p>``TEXT</p>
<p>./ |-- README.md |-- carry-throw-sit.png |-- run-pick-wave.png |-- stand-walk-clap.png |-- wave-clap-walk.png |-- cal_0875.avi |-- cal_2065.avi |-- cal_2935.avi |-- cal_4715.avi |-- carry-throw-sit | |-- 000.mat | |-- 001.mat | |-- 002.mat | |-- 003.mat | |-- 004.mat | |-- 005.mat | |-- 006.mat | |-- 007.mat | |-- 008.mat | |-- 009.mat | |-- 010.mat | |-- 011.mat | |-- 012.mat | |-- 013.mat | |-- 014.mat | |-- 015.mat | |-- 016.mat | |-- 017.mat | |-- 018.mat | |-- 019.mat | |-- 020.mat | |-- 021.mat | |-- 022.mat | |-- 023.mat | |-- 024.mat | |-- 025.mat | |-- 026.mat | |-- 027.mat | |-- 028.mat | |-- 029.mat | |-- 030.mat | |-- 031.mat | |-- 032.mat | |-- 033.mat | |-- 034.mat | |-- 035.mat | |-- 036.mat | |-- 037.mat | |-- 038.mat | |-- 039.mat | |-- 040.mat | |-- 041.mat | |-- 042.mat | |-- 043.mat | |-- 044.mat | |-- 045.mat | |-- 046.mat | |-- 047.mat | |-- 048.mat | |-- 049.mat | |-- 050.mat | |-- 051.mat | |-- 052.mat | |-- 053.mat | |-- 054.mat | |-- 055.mat | |-- 056.mat | |-- 057.mat | |-- 058.mat | <code>-- 059.mat |-- run-pick-wave |   |-- 000.mat |   |-- 001.mat |   |-- 002.mat |   |-- 003.mat |   |-- 004.mat |   |-- 005.mat |   |-- 006.mat |   |-- 007.mat |   |-- 008.mat |   |-- 009.mat |   |-- 010.mat |   |-- 011.mat |   |-- 012.mat |   |-- 013.mat |   |-- 014.mat |   |-- 015.mat |   |-- 016.mat |   |-- 017.mat |   |-- 018.mat |   |-- 019.mat |   |-- 020.mat |   |-- 021.mat |   |-- 022.mat |   |-- 023.mat |   |-- 024.mat |   |-- 025.mat |   |-- 026.mat |   |-- 027.mat |   |-- 028.mat |   |-- 029.mat |   |-- 030.mat |   |-- 031.mat |   |-- 032.mat |   |-- 033.mat |   |-- 034.mat |   |-- 035.mat |   |-- 036.mat |   |-- 037.mat |   |-- 038.mat |   |-- 039.mat |   |-- 040.mat |   |-- 041.mat |   |-- 042.mat |   |-- 043.mat |   |-- 044.mat |   |-- 045.mat |   |-- 046.mat |   |-- 047.mat |   |-- 048.mat |</code>-- 049.mat |-- stand-walk-clap | |-- 000.mat | |-- 001.mat | |-- 002.mat | |-- 003.mat | |-- 004.mat | |-- 005.mat | |-- 006.mat | |-- 007.mat | |-- 008.mat | |-- 009.mat | |-- 010.mat | |-- 011.mat | |-- 012.mat | |-- 013.mat | |-- 014.mat | |-- 015.mat | |-- 016.mat | |-- 017.mat | |-- 018.mat | |-- 019.mat | |-- 020.mat | |-- 021.mat | |-- 022.mat | |-- 023.mat | |-- 024.mat | |-- 025.mat | |-- 026.mat | |-- 027.mat | |-- 028.mat | |-- 029.mat | |-- 030.mat | |-- 031.mat | |-- 032.mat | |-- 033.mat | |-- 034.mat | |-- 035.mat | |-- 036.mat | |-- 037.mat | |-- 038.mat | |-- 039.mat | |-- 040.mat | |-- 041.mat | |-- 042.mat | |-- 043.mat | |-- 044.mat | |-- 045.mat | |-- 046.mat | |-- 047.mat | |-- 048.mat | |-- 049.mat | |-- 050.mat | |-- 051.mat | |-- 052.mat | |-- 053.mat | |-- 054.mat | |-- 055.mat | |-- 056.mat | |-- 057.mat | <code>-- 058.mat</code>-- wave-clap-walk |-- 000.mat |-- 001.mat |-- 002.mat |-- 003.mat |-- 004.mat |-- 005.mat |-- 006.mat |-- 007.mat |-- 008.mat |-- 009.mat |-- 010.mat |-- 011.mat |-- 012.mat |-- 013.mat |-- 014.mat |-- 015.mat |-- 016.mat |-- 017.mat |-- 018.mat |-- 019.mat |-- 020.mat |-- 021.mat |-- 022.mat |-- 023.mat |-- 024.mat |-- 025.mat |-- 026.mat |-- 027.mat |-- 028.mat |-- 029.mat |-- 030.mat |-- 031.mat |-- 032.mat |-- 033.mat |-- 034.mat |-- 035.mat |-- 036.mat |-- 037.mat |-- 038.mat |-- 039.mat |-- 040.mat |-- 041.mat |-- 042.mat |-- 043.mat |-- 044.mat |-- 045.mat |-- 046.mat |-- 047.mat |-- 048.mat |-- 049.mat |-- 050.mat |-- 051.mat |-- 052.mat |-- 053.mat |-- 054.mat |-- 055.mat |-- 056.mat |-- 057.mat |-- 058.mat |-- 059.mat |-- 060.mat `-- 061.mat</p>
<p>``</p>
</body>
</html>
